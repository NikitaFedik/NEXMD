% book example for classicthesis.sty

\documentclass[12pt,letter,footinclude=true,headinclude=true,hyphens]{book} % KOMA-Script book
% scrbook = KOMA-Script book
\usepackage[T1]{fontenc}
\usepackage[hyphens]{url}
\usepackage{lipsum}
\usepackage[linedheaders,parts,pdfspacing]{classicthesis_mod} % ,manychapters
%\usepackage[osf]{libertine}
\usepackage{amsthm}

\begin{document}
%	\pagestyle{scrheadings}
%	\manualmark
%	\markboth{\spacedlowsmallcaps{\contentsname}}{\spacedlowsmallcaps{\contentsname}}


\author{Manual by Dmitri Svetlov and Josiah Bjorgaard \\Los Alamos National Laboratory\\}
\date{Last updated Oct. 20, 2016}
\title{\texttt{NAESMD}: A software package for non-adiabatic and excited-state molecular dynamics}
	
	\maketitle
	
	\tableofcontents 

%	\automark[section]{chapter}
%	\renewcommand{\chaptermark}[1]{\markboth{\spacedlowsmallcaps{#1}}{\spacedlowsmallcaps{#1}}}
%	\renewcommand{\sectionmark}[1]{\markright{\thesection\enspace\spacedlowsmallcaps{#1}}}

    % use \cleardoublepage here to avoid problems with pdfbookmark
    \cleardoublepage\part{Getting Started}
    
    \chapter{Introduction}
    
    This is a manual for the \texttt{NAESMD} package developed at Los Alamos National Laboratory under the direction of Sergei Tretiak. It simulates the photoinduced adiabatic and non-adiabatic ground- and excited-state molecular dynamics of organic chromophores. It uses the \texttt{CEO} (collective electronic oscillator) package with a variety of semiempirical methods from the \texttt{SQM} package. Tully's fewest-switches surface hopping approach to quantum transitions is employed, with instantaneous decoherence and a Min-Cost algorithm for the detection of trivial unavoided crossings. Several TD-SCF (time-dependent self-consistent field) QM/continuum models are available for including the effects of a solvent.
    
    \chapter{Authors}
    
    J.A. Bjorgaard, K. A. Velizhanin, S. Falberti, S. Tretiak
    
    \chapter{Terms of Use}
    
    GPL
    
    \chapter{Installation}
    
    The distribution of \texttt{NAESMD} contains all code necessary to utilize the entire package (provided that effective compilers for Fortran 90/95 and ANSI C are available). Makefiles are provided for the benefit of those computing in a Unix-based environment; these have been used successfully by our group to compile the software on our own HPC clusters. However, we cannot guarantee that any makefile will successfully compile  \texttt{NAESMD} on a given infrastructure with no changes needed.
    
    To compile \texttt{NAESMD}, change into the top-level directory of the package and modify the provided Makefile to give the desired compilers (default of gfortran and gcc) and provide compiled BLAS and LAPACK libraries. Then run
    
    \texttt{make all}

or if using LANL IC systems, run

    \texttt{make all\_ic}

after loading relevant intel compiler and MKL modules.    
    
    \part{Methodology and Preparation of Input Files}
    
    This part is structured according to the general input file used by the entire package. For each section of input or group of closely related parameters, it briefly discusses the relevant underlying methodology and physics (assuming only a first course in quantum mechanics) and then describes how to configure the input for the system of interest. Some parameters are for features which are still under development. These features are flagged by the (prototype) keyword. A link is included at the start of each section on methodology allowing readers who are familiar with it to skip ahead. Our hope is that this guide can thus effectively serve both mature researchers who are merely new to our software and beginning students with little to no background in the field of non-adiabatic molecular dynamics. References to the texts used and to additional resources are given in the bibliography.
    
    \chapter{Electronic/Molecular Structure}
    
    \label{electronic-structure-intro}
    
    Predicting the dynamical evolution of a chemical system requires first knowing the various states in which it can exist - here, these are its ground and excited electronic states. Ascertaining these is a task for computational quantum chemistry and one that cannot be completed with perfect accuracy for all but the simplest of molecular systems. Every practical methodology must therefore make some trade-off between computational tractability and chemical correctness. A broad discussion of the available techniques is beyond the scope of this manual; the coverage will be limited to Hartree-Fock theory, its extensions to excited-state calculations, and the inclusion of solvent models. (If you have not encountered the Born-Oppenheimer approximation or the electronic Hamiltonian, skip ahead briefly to \ref{molecular-dynamics-intro} to familiarize yourself with the notation and rationale.)
    
    \section{Hartree-Fock Theory: Ground State Calculations}
    
    Skip ahead to \ref{ground-state-input}
    
    Recall from basic quantum mechanics that the hydrogen atom is the simplest system containing both a nucleus and an electron for which the Schr\"{o}dinger equation can be solved exactly. Now consider a multi-electron atom. If the electrons did not interact with one another, the electronic repulsion energy $V_{ee}(\mathbf{r})$ would be zero, the Hamiltonian would be separable, and the total electronic wavefunction would be a simple - and symmetric - product of the wavefunctions of the individual electrons:
    
    \begin{equation}
    \Psi_{HF}(\mathbf{r}) = \psi(\mathbf{r}_1)\psi(\mathbf{r}_2) \cdot \cdot \cdot \psi(\mathbf{r}_n)
    \end{equation}
    
    However, since electrons are fermions, electronic wavefunctions must be antisymmetric with respect to the exchange of any two electrons (and thus their space-spin coordinates). The easiest way to remedy this is to (1) replace the \emph{spatial} wavefunctions/orbitals $\psi$ above with \emph{spin} orbitals $\chi$, by multiplying them with either the $\alpha$ or $\beta$ spin function; (2) changing thus from spatial coordinates $\mathbf{r}$ to spin coordinates $\mathbf{x}$ and (2) defining the total wavefunction as a normalized determinant of those spin functions:
    
    \begin{equation}
    \Psi_{HF} = \frac{1}{\sqrt{N!}}\left| \begin{array}{cccc}
        \chi_1(\mathbf{x}_1) & \chi_2(\mathbf{x}_1) & \mathellipsis & \chi_n(\mathbf{x}_1)  \\
        \chi_1(\mathbf{x}_2) & \chi_2(\mathbf{x}_2) & \mathellipsis & \chi_n(\mathbf{x}_2)  \\
        \vdots & \vdots & \ddots & \vdots  \\
        \chi_1(\mathbf{x}_n) & \chi_2(\mathbf{x}_n) & \mathellipsis & \chi_n(\mathbf{x}_n)  \end{array} \right|
    \end{equation}
    
    The exchange of any two electrons will change the sign of the total wavefunction, since exchanging any two rows or columns of a matrix negates the value of its determinant. This formulation also directly entails that electrons are indistinguishable and obey the Pauli exclusion principle.
    
    To evaluate these eigenfunctions, we will rewrite the Hamiltonian by defining the \emph{one-electron operator}
    
    \begin{equation}
    h(i) = -\frac{1}{2}\nabla_i^2 - \sum_A \frac{Z_A}{r_{iA}}
    \end{equation}
    
    and the \emph{two-electron operator}
    
    \begin{equation}
    v(i,j) = \frac{1}{r_{ij}}.
    \end{equation}
    
    The electronic Hamiltonian then becomes
    
    \begin{equation}
    H_e = \sum_i h(i) + \sum_{i < j} v(i,j) + V_{NN},
    \end{equation}
    
    and since we are working in an adiabatic basis and thus fixing the set of nuclear coordinates $\{\mathbf{R}\}$, $V_{NN}$ will be a constant that we can ignore without any change to the eigenfunctions. We can then employ a variational approach to find the electronic energy. In general, we have
    
    \begin{equation}
    E_e = \left < \Psi | H_e | \Psi \right >.
    \end{equation}
    
    It can be shown that the \emph{Hartree-Fock energy} is a function of integrals of the one- and two-electron operators introduced above:
    
    \begin{equation}
    E_{HF} = \sum_i \left < i | h | i \right > + \frac{1}{2} \sum_{ij} \left [ ii | jj \right ] - \left [ ij | ji \right ]
    \end{equation}
    
    \begin{equation}
    \left < i | h | j \right > = \int d\mathbf{x}_1 \chi_i^* (\mathbf{x}_1)  h(\mathbf{r}_1) \chi_j (\mathbf{x}_1)
    \end{equation}
    
    \begin{equation}
    \left [ ij | kl \right ] = \int d\mathbf{x}_1 d\mathbf{x}_2 \chi_i^* (\mathbf{x}_1) \chi_j (\mathbf{x}_1) \frac{1}{r_{12}}  \chi_k^* (\mathbf{x}_2) \chi_l (\mathbf{x}_2)
    \end{equation}
    
    The variational principle tells us that the solution to this equation (i.e., its eigenvalue) is an upper bound on the actual ground-state energy of the system; in particular, we have obviously neglected the energy resulting from electron-electron repulsion, so we cannot obtain the true minimum energy.
    
    Computationally, these operators are represented in matrix form and the eigenvalue equations that result are solved via matrix diagonalization. However, the matrices depend on their own solutions (which will be linear combinations of the orbital bases we choose). Therefore, the euqation can only be solved iteratively: starting from a reasonable initial guess of orbitals, the electron density and total energy (including nuclear repulsions) are computed. These are then used as updated guesses, and new densities and energies are computed. This process is repeated until a set number of iterations have been completed or until the energies and densities \emph{converge} (i.e., the change in each from one iteration to the next is below a target value). Because of these aspects, this is known as a \emph{self-consistent field} method.
    
    In addition to purely \emph{ab initio} methods such as these, there are also \emph{semiempirical} methods that employ system-specific parameters derived from experimental data to formulate approximations of the true Hamiltonian that sacrifice chemical accuracy but are easier to solve. The earliest and perhaps most influential is the H\"{u}ckel model for conjugated $\pi$ systems, which uses a "tight-binding" approach where each carbon atom has a single $p$ orbital, overlap integrals between non-identical atoms are taken to be zero, and only two parameters, the Coulomb integral and resonance/bond integral, are required. These parameters have been established by experiment, and the model has yielded qualtitatively - and sometimes quantitatively - useful insights.
    
    For example, \texttt{NAESMD} uses the method of \emph{collective} (or \emph{coupled}) \emph{electronic oscillators} developed by Mukamel and colleagues in the calculation of electronic structures. This combines the Pariser-Parr-Pople (PPP) tight-binding Hamiltonian and the single-electron density matrix in the ground state with time-dependent Hartree-Fock theory to arrive at a set of electronic "normal modes" that are in many ways analogous to their nuclear counterparts. The advantage of this approach is that in many applications - such as the nonlinear optical responses of conjugated polyenes - only a few such oscillators tend to be important. Thus we are still able to capture many important phenomena and trends, but with significant computational savings.
    
    The latest version of \texttt{NAESMD} interfaces with the \texttt{sqm} package to provide a variety of semiempirical models, listed in the table of input parameters below.
    
    Finally, the package provides three methods for dealing with the computationally intensive problem of SCF iteration at each time step of the molecular dynamics simulation. In order to ensure adiabatic evolution of the trajectory, forces must always be calculated at the electronic ground state. Earlier approaches "propagated" combinations of the ground-state configurations from previous time steps as initial guesses to subsequent SCF calculations. While this reduces the number of iterations necessary, it also introduces systematic energy drifts, because electronic evolution is irreversible until SCF convergence is attained. As a result, methodologies such as time-reversible Born-Oppenheimer molecular dynamics (TR-BOMD), and an "extended Lagrangian" formulation (XL-BOMD) of it, have recently been developed to allow for higher-order symplectic schemes that produce physically meaningful results while preserving computational efficiency. \texttt{NAESMD} allows all three approaches.     
    
    \subsection{Configuring the Input}
    \label{ground-state-input}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{qm\_theory} & 'MNDOD' & The approach to computing the HF integrals; consult additional references for more on each method and selecting the one that is optimal for your simulation. NOTE: Currently only the AM1 has been thoroughly tested in this package\\
    & 'AM1' & \\
    & 'AM1D' & \\
    & 'PM3' & \\
    & 'PM3CARB1' & \\
    & 'PM3ZNB' & \\
    & 'PM3MAIS' & \\
    & 'PM6' & \\
    & 'PDDGPM3' & \\
    & 'PDDGPM3\_08' & \\
    & 'PDDGMNDO' & \\
    & 'RM1' & \\
    & 'DFTB' & \\
    \hline
    \texttt{scfconv} & X.Yd-Z & The convergence criterion for the ground-state SCF calculation, equal to $\mathrm{X.Y} \cdot 10^{-\mathrm{Z}}$ in units of electron-volts \\
    \hline
    \texttt{verbosity} & INTEGER & An integer between 0 (least output) and 5 (most) [Increasing the verbosity slows down the simulation and writes more data to disk. Consider a few short test calculations to determine the minimum level of verbosity needed for your purpose.]\\
    \hline
    \texttt{printcharges} & $1$ & Prints Mulliken charges for the ground-state configuration \\
    & $0$ & Does not print Mulliken charges \\
    \hline
    \texttt{printdipole} & $2$ & Prints relaxed and unrelaxed ground-state dipoles \\
    & $1$ & Prints transition dipole matrix \\
    & $0$ & Prints no dipole information \\ \hline
    \texttt{printbondorders} & $1$ & Prints bond orders in the ground-state configuration \\
    & $0$ & Does not print bond orders \\ \hline
    \end{tabular}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{density\_predict} & $0$ & Standard HF-SCF where required \\
    & $1$ & Reversible Born-Oppenheimer MD (prototype) \\
    & $2$ & Extended Lagrangian formulation of Born-Oppenheimer MD (XL-BOMD) (prototype) \\ \hline
    \texttt{K} & INTEGER & An integer between 3 and 9 inclusive; used as the parameter for XL-BOMD and irrelevant otherwise \\ \hline
    \texttt{itrmax} & INTEGER & Maximum number of SCF iterations for the ground-state calculations [A negative integer signifies that convergence will be ignored.]\\
    \hline
    \end{tabular}
    
    \section{Excited-State Calculations}
    
    Skip ahead to \ref{excited-state-input}
    
    As Hartree-Fock theory is the simplest \emph{ab initio} approach to ground-state electronic structure calculations, its extensions are the simplest ones to solving the structures of excited states. The package implements the two most basic: configuration interaction singles (CIS) and time-dependent Hartree-Fock theory (TD-HF), which is also known as the random-phase approximation (RPA).
    
    CIS uses the ground-state HF wavefunction as a starting point for creating singly-excited determinants ("singles"); this is done by exchanging the occupancies of an unoccupied spin orbital with an occupied one. Excited-state wavefunctions are then expressed as linear combinations of these determinants. No additional information is needed, since this can be achieved using the Fock matrix elements and two-electron integrals used in solving for the ground-state wavefunction. A combinatorial challenge is introduced because multiple spin configurations will necessarily be available to the excited molecule. Therefore, if we are only interested in, for instance, triplet excited states, we can "spin-adapt" CIS to utilize only spatial rather than spin orbitals, which leads to a Hamiltonian matrix that is four times smaller and eight times faster to diagonalize.
    
    RPA is similar to CIS in that it also uses only singles - and indeed, the CIS matrix itself - but it involves additional excitation and de-excitation operators. In a na\"{\i}ve implementation, this yields an eigenvalue problem with twice the dimensions (and thus four times the storage size) of an equivalent CIS; however, a creative rearrangement reduces the problem to one of identical size.
    
    Each of these approaches faces the challenge of very large matrices that must be diagonalized - specifically, ones with dimensions at least as large as the product of the number of occupied orbitals and the number of unoccupied ones. For all but the smallest molecules, such matrices will not fit in core memory, and thus algorithms like the one by Ernest Davidson, or its extension by Bowen Liu, must be used. The algorithm works as follows:
    
    \begin{enumerate}
    \item Select reasonable "guess vectors", at least one for each desired eigenvalue (root).
    \item Construct a "subspace" Hamiltonian within the space of guess vectors.
    \item Build a set of "correction vectors," which depend on the diagonal terms of the Hamiltonian and on "residual vectors," which are defined such that they are zero if their corresponding guess vectors are equal to the true eigenvectors. At this point, check the norms of the residuals and the changes in the corresponding eigenvalues for convergence.
    \item Normalize each correction vector and orthogonalize it against the set of guess vectors. Check its norm against a minimum threshold; discard it if it does not reach that threshold.
    
    Return to Step 2.
    \end{enumerate}
    
    \subsection{Configuring the Input}
    \label{excited-state-input}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{exst\_method} & $1$ & Configuration interaction singles (CIS) \\
    & $2$ & Random-phase approximation (RPA/TD-HF) \\ \hline
    \texttt{dav\_guess} & $2$ & Davidson diagonalization will use XL-BOMD to provide starting guesses \\
    & $1$ & Previous configurations will be used as starting guesses \\
    & $0$ & Diagonalization will start from scratch every time \\ \hline
    \texttt{ftol} & X.dY & Minimum threshhold for retention of normalized vectors $\left ( e_{min} - e_{old} \right )$ for diagonalization, equal to $\mathrm{X} \cdot 10^{-\mathrm{Y}}$ in units of electron-volts \\ \hline
    \texttt{ftol0} & X.Yd-Z & Acceptance energy tolerance $\left ( e_{min} - e_{old} \right )$ for diagonalization, equal to $\mathrm{X.Y} \cdot 10^{-\mathrm{Z}}$ in units of electron-volts \\ \hline
    \texttt{ftol1} & X.Yd-Z & Minimum residual-norm tolerance $\left ( e_{min} - e_{old} \right )$ for diagonalization, equal to $\mathrm{X} \cdot 10^{-\mathrm{Y}}$ in units of electron-volts \\ \hline
    \texttt{dav\_maxcyc} & INTEGER & Maximum number of Davidson diagonalization cycles for the excited-state calculations [A negative integer signifies that a fixed number (its arithmetic inverse) will be performed.] \\ \hline
    \end{tabular}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{printtd} & $-1$ & Prints binary files \texttt{modes.b} and \texttt{ee.b} \\
    & $0$ & Prints no information about transition densities \\
    & $1$ & Prints transition densities in the molecular-orbital representation \\
    & $2$ & Prints transition densities in the atomic- and molecular-orbital representations \\
    & $3$ & Same as $2$, and fit NDDO charges \\
    \hline
    \texttt{calcxdens} & \texttt{.true.} & Calculate cross-density dipole moments/oscillator strengths \\
    & \texttt{.false.} & Do not calculate cross-density dipole moments/oscillator strengths \\
    \hline
    \end{tabular}
    
    \section{Geometry Optimization}
    
    Skip ahead to \ref{geo-opt-input}
    
    Geometry optimization will attempt to alter the arrangement of the nuclei in order to minimize the total energy. Depending on your simulation and the stage within it, this optimal geometry may be desired, or it may not - for example, geometry optimization should not (be forced to) occur during a state transition.)
    
    \subsection{Configuring the Input}
    \label{geo-opt-input}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{maxcyc} & INTEGER & Number of cycles of geometry optimization that will be performed; if $0$ is used, the system will be "frozen" in the provided coordinates for electronic-structure calculations. \\ \hline
    \texttt{ntpr} & INTEGER & Results will be printed after every \texttt{ntpr} cycle(s). \\ \hline
    \texttt{grms\_tol} & DOUBLE & Tolerance of energy derivatives, in units of electron-volts per angstrom, to be used for optimization \\
    \hline
    \end{tabular}
    
    \section{Solvent Models}

    Skip ahead to \ref{solvent-models-input}
    
    The presence of a solvent can have significant effects on photodynamics. It is not computationally feasible to treat both a solute and a sufficient environment of solvent molecules quantum mechanically; therefore, the solute is treated quantum mechanically and the solvent is treated either molecular mechanically (a QM/MM approach) or as a polarizable continuum (QM/continuum) forming cavities in which solutes are enclosed. The latest version of \texttt{NAESMD} implements a QM/continuum treatment within the linear response (LR), vertical excitation (VE), and state-specific (SS) models. For more details, refer to our publications on "Solvent Effects in TD-SCF."
    
    \subsection{Configuring the Input}
    \label{solvent-models-input}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{ceps} & INTEGER & Dielectric constant \\ \hline
    \texttt{index\_of\_refraction} & INTEGER & Dielectric constant for excitation (prototype - program currently uses ceps dielectric contant for everything) \\ \hline
    \texttt{nspa} & INTEGER & Approximate number of solvent cavity points per atom \\ \hline
    \texttt{cosmo\_scf\_ftol} & X.Yd-Z & SCF tolerance for SS model, given as $\mathrm{X.Y} \cdot 10^{-\mathrm{Z}}$ in units of electron-volts \\ \hline
    \texttt{cosmo\_scf\_maxcyc} & INTEGER & Maximum number of SCF iterations for SS model \\ \hline
    \texttt{linmixparam} & INTEGER & Linear mixing parameter for state-specific solvent iterations \\ \hline
    \texttt{doZ} & \texttt{.true.} & Calculate relaxed electron density in COSMO of SS model \\
    & \texttt{.false.} & Calculate unrelaxed electron density in COSMO of SS model \\ \hline
    \texttt{EF} & $1$ & Include electric field for ground and excited states \\
    & $0$ & Include electric field only for excited states \\ \hline
    \texttt{Ex} & INTEGER & $x$-component of electric field vector \\ \hline
    \texttt{Ey} & INTEGER & $y$-component of electric field vector \\ \hline
    \texttt{Ez} & INTEGER & $z$-component of electric field vector \\ \hline
    \texttt{onsager\_radius} & INTEGER & Onsager cavity radius \\ \hline
    \texttt{solvent\_model}
    & $4$ & SS model \\
    & $3$ & VE model prototype \\
    & $2$ & VE model \\
    & $1$ & LR model \\
    & $0$ & No solvent (gas phase) \\ \hline
    \texttt{potential\_type} & $4$ & [Used only for testing] \\
    & $3$ & COSMO \\
    & $2$ & Onsager \\
    & $0$ & Normal correlation (prototype) \\
    \hline
    \end{tabular}
    
    \chapter{Molecular Dynamics}
    
    \label{molecular-dynamics-intro}
    
    Skip ahead to \ref{general-parameters}
    
    Molecular dynamics (MD) simulations are used to predict how a given collection of atoms and molecules will behave under certain conditions (e.g. temperatures, pressures, electric fields). Classical physics holds that Newton's three laws of motion completely describe all mechanics. These involve only the mass, position, velocity, and acceleration of each particle and all interactive forces among the particles, which also affect their accelerations. A classical MD simulation therefore reduces to solving a system of differential equations, each one second-order in time, given a set of initial conditions. Using this solution, we can calculate any property of the system as an explicit function of time and its average value over a period of time.
    
    Quantum MD rests on different postulates; namely, that all material systems are wavelike in nature, that the wavefunctions characterizing them are all solutions to the Schr\"{o}dinger equation, and that all properties of a system can be calculated if its wavefunction is exactly known. A quantum MD simulation thus involves solving a single differential equation (the time-dependent Schr\"{o}dinger equation), likewise second-order in time, to obtain the wavefunction describing the entire system at each point in time. The fundamental challenge in computational chemistry is that no analytical solutions for molecular systems exist, and numerical solution methods require trade-offs between accuracy and tractability.
    
    A common first step in such simulations, and one that often yields tremendous reductions in computational cost, is the separation of electronic motions from nuclear ones. Consider the Hamiltonian operator for a general system described by electronic coordinates $\mathbf{r}$ and nuclear coordinates $\mathbf{R}$:
    
    \begin{equation}
    H(\mathbf{r}, \mathbf{R}) = T_N(\mathbf{R}) + \underbrace{T_e(\mathbf{r}) + V_{ee}(\mathbf{r})}_{H_e(\mathbf{r})} + V_{eN}(\mathbf{r}, \mathbf{R})
    \end{equation}
    
    Here, $T_e$ and $T_N$ are the electronic and nuclear kinetic-energy operators, respectively, $V_{eN}$ is the potential-energy operator including all electron-nuclear and nuclear-nuclear interactions, and $H_e$ is the "electronic Hamiltonian" composed of purely electronic contributions to the energy: the kinetic energy of all electrons and the potential energy due to all electron-electron repulsions.
    
    Now suppose that all nuclei were fixed in space. We can then exclude $T_N$ from the Hamiltonian and write the Schrodinger equation as
    
    \begin{equation}
    \left[ H_e(\mathbf{r}) + V_{eN}(\mathbf{r}; \mathbf{R}) \right] \phi_{\alpha}(\mathbf{r}; \mathbf{R}) = \epsilon_{\alpha}(\mathbf{R})\phi_{\alpha}(\mathbf{r}; \mathbf{R})
    \end{equation}
    
    where the eigenfunctions $\phi_{\alpha}(\mathbf{r}; \mathbf{R})$ depend parametrically on the fixed $\mathbf{R}$, have eigenvalues $\epsilon_{\alpha}(\mathbf{R})$, and are denoted as the \textit{adiabatic basis functions}.
    
    Allowing all possible values of $\mathbf{R}$, the set of (orthonormal) adiabatic basis functions forms a complete basis, and we can write the total time-dependent molecular wavefunction as
    
    \begin{equation}
    \Psi(\mathbf{r}, \mathbf{R}, t) = \sum_{\alpha} c_{\alpha}(t) \phi_{\alpha}(\mathbf{r}; \mathbf{R}(t))
    \end{equation}
    
    where $c_{\alpha}(t)$ are the time-dependent expansion coefficients. The equation of motion for these coefficients then becomes
   
    \begin{equation}
    i \hbar \dot{c}_{\alpha}(t) = c_{\alpha}(t) E_{\alpha}(\mathbf{R}) - i \hbar \sum_{\beta} c_{\beta}(t) \dot{\mathbf{R}} \cdot \mathbf{d}_{\alpha \beta}.
    \end{equation}
    
    Here, $\mathbf{d}_{\alpha \beta} = \left < \phi_{\alpha}(\mathbf{r}; R) \left | \nabla_{R} \phi_{\beta}(\mathbf{r}; R) \right . \right >$ is the NA coupling vector (NACV) and $\dot{\mathbf{R}} \cdot \mathbf{d}_{\alpha \beta} = \left < \phi_{\alpha}(\mathbf{r}; R) \left | \partial \phi_{\beta}(\mathbf{r}; R) / \partial t \right . \right >$ is the NA coupling scalar term (NACT).
    
    \section{General Parameters}
    \label{general-parameters}
    
    Skip ahead to \ref{general-parameters-input} or return to \ref{molecular-dynamics-intro}
    
    These first parameters in the molecular-dynamics section of the input determine the most fundamental aspects of the simulation: whether state transitions will be allowed (non-adiabatic, or non-Born-Oppenheimer, dynamics) or not (adiabatic; Born-Oppenheimer), the initial state of the system, and which states will be accessible to the system over the course of the simulation.
    Also, since state transitions in non-adiabatic dynamics are made stochastically, an integer seed is provided for the pseudorandom number generator used.
    
    \subsection{Configuring the Input}
    \label{general-parameters-input}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{natoms} & INTEGER & This is the maximum number of atoms that can be used in the simulation. Setting to the exact number of atoms used in the simulation gives the best memory performance.\\
    \hline
    \texttt{rnd\_seed} & INTEGER & An integer seed for the random number generator used [this value is irrelevant for single-point calculations].\\
    \hline
    \texttt{bo\_dynamics\_flag} & $0$ & non-Born-Oppenheimer/non-adiabatic dynamics [state transitions allowed].\\
    & $1$ & Born-Oppenheimer/adiabatic dynamics [state transitions forbidden].\\
    \hline
    \texttt{exc\_state\_init} & INTEGER & Initial state: $0$ denotes the ground state, $1$ the first excited state, etc.\\
    \hline
    \texttt{n\_exc\_states\_propagate} & INTEGER & Number of excited states to include in the calculations [This number is \emph{critical} for all simulations except for adiabatic dynamics. Excited states above this number do not exist as far as the program is concerned.]\\
    \hline
    \end{tabular}
    
    \section{Dynamics Parameters}
    \label{dynamics-parameters}
    
    Skip ahead to \ref{dynamics-parameters-input}
    
    The system evolves over a window time discretized into both classical and quantum time points. These are separated by constant \emph{time steps} $\Delta t$ (classical) and $\delta t$ (quantum), with $\delta t < \Delta t$ because electronic dynamics are much faster than those of nuclei; large quantum steps are not sufficient for resolving NACT peaks that are strongly localized, leading to underestimated state transition probabilities.
    
    At each intermediate $\delta t$, the energies of all excited states and NACTs between all pairs thereof are calculated. These are also determined at each classical time step, but subsequently, the electronic state coefficients are updated according to the equation of motion above. For non-adiabatic dynamics, switching probabilities $g_{\alpha \beta}$ are also evaluated, as a summation over all $N_q = \frac{\Delta t}{\delta t}$ quantum steps made since the previous classical time step:
    
    \begin{equation}
    g_{\alpha \beta} = \frac{\sum_{j=1}{N_q} b_{\beta \alpha}(j) \delta t}{a_{\alpha \alpha}}
    \end{equation}
    
    These terms $a$ and $b$ are explained in the following subsection on non-adiabatic parameters.
    
    \subsection{Configuring the Input}
    \label{dynamics-parameters-input}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{time\_init} & X.dY & The initial simulation time, given as $X \cdot 10^Y$ femtoseconds; this can be set to a non-zero time to restart a previous simulation at the corresponding time step. \\ \hline
    \texttt{time\_step} & DOUBLE & Time step, in units of femtoseconds \\ \hline
    \texttt{n\_class\_steps} & INTEGER & Number of classical simulation steps, leading to a total simulation time of \texttt{n\_class\_steps} $\times$ \texttt{time\_step} femtoseconds. \\ \hline
    \texttt{n\_quant\_steps} & INTEGER & Number of quantum simulation steps per classical step \\ \hline
    \texttt{moldyn\_deriv\_flag} & $2$ & Derivatives calcualted by finite-difference) \\
    & $1$ &Derivatives calculated analytically \\
    & $0$ &Derivatives are set to zero \\ \hline
    \texttt{num\_deriv\_step} & X.Yd-Z & Displacement used in calculating numerical derivatives, in units of angstroms \\ \hline
    \texttt{rk\_tolerance} & X.d-Y & Tolerance for the Runge-Kutta propagator. \\
    \hline
    \end{tabular}
    
    \section{Non-adiabatic and Decoherence Parameters}
    
    Skip ahead to \ref{na-input}
    
    In non-adiabatic dynamics, quantum transitions are permissible. \texttt{NAESMD} uses John Tully's \emph{fewest-switches surface hopping} (FSSH) algorithm, whose validity has been demonstrated across a variety of systems. In this approach, a system evolves along the potential energy surface (PES) of a single electronic state, with nuclei treated classically and electrons quantum-mechanically; this continues until a "hop" (quantum transition) between states occurs. A single trajectory can illustrate mechanistic aspects of the underlying photophysics; a statistical ensemble (or "swarm") of many independent trajectories can yield observables such as branching ratios, non-radiative relaxation rates, quantum yields, and so on.
    
    The probability of such a hop from a current state $\alpha$ to another state during a given classical time step $\Delta t$ is given by
    
    \begin{equation}
    \dot{a}_{\alpha \alpha}(t) = \sum_{\beta \neq \alpha} b_{\alpha \beta}
    \end{equation}
    
    where 
    
    \begin{equation}
    b_{\alpha \beta}(t) = -2 \textrm{Re} \left ( a_{\alpha \beta}^* \dot{\mathbf{R}} \cdot \mathbf{d}_{\alpha \beta} \right ). 
    \end{equation}
    
    Hops are accepted or rejected stochastically; if the nuclear kinetic energy is insufficient to allow a particular hop to a higher state, that hop is classically forbidden and rejected. If the hop is accepted, nuceli evolve on the new PES, and conservation of energy is achieved by rescaling nuclear velocities in the direction of the NACV and by the appropriate amounts.
    
    The FSSH method has the drawback that because it propagates quantum coefficients coherently on each trajectory, electronic coherence cannot be dissipated in any single-trajectory simulation. As a result, the classical and quantum "occupancies" of a given state will diverge from one another over the course of the simulation. To resolve this, our code utilizes the \emph{instantaneous decoherence} approach, in which the quantum population of the current state is reset to unity at each classical time step (where hops are attempted). The rationale is that wavepackets on different surfaces should instantaneously separate in phase space and evolve independently; no single trajectory should thus have any quantum amplitude in two states at once.
    
    One final point concerns the problem of \emph{unavoided crossings}. These events can significantly effect photochemistry and can occur readily in conjugated molecules, even between noninteracting states localized in spatially separated portions of the molecule. The latter are called \emph{trivial} unavoided crossings and present a particular numerical challenge, since their NACTs are analogous to strong peaks appearing at the exact intersection and vanishing everywhere else. The numerical propagation of nuclear motion in finite time steps can cause such crossings to go undetected, leading to artifacts in state populations.
    
    \texttt{NAESMD} uses a Min-Cost algorithm (discussed in details in one of our Relevant Publications) to ensure that such trivial crossings are detected and handled properly. This involves the occasional reduction of the quantum time step within individual classical time steps, in order to evaluate more couplings between states that could be relevant to a possible hop, and thus in essence "resolve" the NACT peak. A parameter is used to indicate how many times $\delta t$ should be reduced in each such instance.
    
    \subsection{Configuring the Input}
    \label{na-input}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{quant\_coeffs\_reinit} & $1$ & Quantum coefficients are reinitialized after a hop \\
    & $0$ & Coefficients are not reinitialized after a hop \\ \hline
    \texttt{quant\_step\_reduction\_factor} & X.YdZ & Quantum time step reduction factor for detecting trivial avoided crossings, given as $1/ (\textrm{X.Y} \cdot 10^{\textrm{Z}})$ \\ \hline
    \texttt{decoher\_type} & $1$ & Truhlar decoherence is used \\
    & $0$ & Persicco/Granucci decoherence is used \\ \hline
    \texttt{decoher\_e0} & X.dY & Decoherence parameter $E_0$, given as $\textrm{X} \cdot 10^\textrm{Y}$ \\ \hline
    \texttt{decoher\_c} & X.dY & Decoherence parameter $C$, given as $\textrm{X} \cdot 10^\textrm{Y}$ \\ \hline
        \texttt{dotrivial} & 1 & Track trivial unavoided crossings \\
        & 0 & Do not track trivial unavoided crossings \\ \hline
    \end{tabular}
    
    \section{Thermostat Parameters}
    
    Skip ahead to \ref{thermo-input}
    
    Classical molecular dynamics simulations, integrating Newton's equations of motion, obey the law of energy conservation. Given a fixed system volume and set of particles, these simulations thus reproduce the average thermodynamic properties of a \emph{microcanonical}, or $NVE$, ensemble (fixed particle number $N$, volume $V$, and total energy $E$).
    
    However, in many situations, we are interested in a system equilibrated such that some thermodynamic variable (e.g. temperature) is held constant at a given value. This can be accomplished by creating an $NVE$ supersystem where the surroundings of the (sub)system of interest serve as a bath. \texttt{NAESMD} provides two methods for simulating dynamics under a \emph{thermostat}, i.e. an $NVT$, or \emph{canonical}, ensemble. \\ \\
    The Langevin thermostat combines Langevin dynamics with velocity Verlet integration. A stochastic force $\mathbf{A}$ depends on the bath temperature and a friction coefficient $\gamma$, which also impacts the nuclear velocities in a direct, linear fashion. The excited-state gradients that determine nuclear motion are determined analytically. Due to the presence of the friction coefficient, various fluid-mechanical properties of the system's surroundings can be directly introduced, particularly in simulations where a solute molecule can be treated as the system and a collection of (relatively small) solvent molecules as the supersystem/surroundings. \\ \\
    The Berendsen thermostat multiplies all velocities by an identical $\lambda$ to bring a system at a non-target temperature $T$ closer to the target temperature $T_0$; this is done at each time step and such that the rate of temperature charge is proportional to $T_0 - T$. This thermostat does not technically produce an $NVT$ ensemble; rather, it interpolates between a microcanonical and canonical ensemble based on the value of the \emph{bath relaxation parameter}, which determines the proportionality above.   
    
    \subsection{Configuring the Input}
    \label{thermo-input}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{therm\_type} & $2$ & A Berendsen thermostat is used \\
    & $1$ & A Langevin thermostat is used \\
    & $0$ & No thermostat is used (a constant-energy simulation is performed) \\ \hline
    \texttt{therm\_temp} & XYZ.dN & Thermostat temperature, as $XYZ \cdot 10^N$ K [This is only relevant for $NVT$ ensembles.]\\ \hline
    \texttt{therm\_friction} & XY.dZ & Thermostat friction coefficient, as $XY \cdot 10^Z$ in units of inverse picoseconds [This is only relevant for Langevin thermostats.] \\ \hline
    \texttt{berendsen\_relax\_const} & DOUBLE & Bath relaxation parameter within $(0, \infty)$ [This is only relevant for Berendsen thermostats.] \\ \hline
    \texttt{heating} & $1$ & The system will be heated to \texttt{therm\_temp} \\
    & $0$ & The system is or will be equilibrated at \texttt{therm\_temp}\\ \hline
    \texttt{heating\_steps\_per\_degree} & INTEGER & The number of steps that will be used per degree Kelvin during a heating process [This is not relevant for equilibrated $NVT$ ensembles.] \\ \hline
    \end{tabular}
    
    \section{Output and Log Parameters}
    
    As with the electronic structure calculations, the software allows for a variety of output levels and frequencies in the molecular dynamics simulations, and care should be chosen in setting these values so that simulations are not slowed down needlessly by printing excessive output.
    
    \subsection{Configuring the Input}
    \label{output-log-input}
    
    \begin{tabular}{ | c | c | p{7cm} | }
    \hline
    \texttt{verbosity} & INTEGER & An integer between $0$ (indicating minimal) and $3$ (highest) verbosity of output. \\ \hline
    \texttt{out\_count\_init} & INTEGER & The initial count for output files [Note: Analogous files in the working directory bearing corresponding count numbers will be overwritten.]\\ \hline
    \texttt{out\_data\_steps} & INTEGER & Data will be written to files after every \texttt{out\_data\_steps} time step(s). \\ \hline
    \texttt{out\_coords\_steps} & INTEGER & Coordinate files (which are sufficient to restart a simulation) will be written after every \texttt{out\_coords\_steps} time step(s). \\ \hline
    \texttt{out\_data\_cube} & $1$ & View-files to generate cubes will be written \\
    & $0$ & View-files will not be written \\ \hline
    \end{tabular}
   
    \section{Coordinates, Velocities, and State Coefficients}
    
    Coordinates are specified in a standard \texttt{XYZ} format as
    
    \begin{center}
    \begin{tabular}{ | c | c | c | c | } \hline
    $Z_1$ & $x_1$ & $y_1$ & $z_1$ \\ \hline
    $Z_2$ & $x_2$ & $y_2$ & $z_2$ \\ \hline
    $Z_3$ & $x_3$ & $y_3$ & $z_3$ \\ \hline
    ... & ... & ... & ... \\ \hline
    \end{tabular}
    \end{center}
    
    where $Z_i$ denotes the atomic number and $x_i,\ y_i,\ z_i$ the coordinates (in angstroms) of atom $i$. In preparing initial conditions for a single-point calculation or ground-state adibatic trajectory, these coordinates can be obtained from a molecular builder, such as Avogadro (\url{http://avogadro.org/}) or IQmol (\url{http://iqmol.org/}), applying an optimization procedure, if needed or desired, to obtain a reasonable initial geometry.
    
    Velocities are specified analogously, in units of angstroms per atomic time units, for each Cartesian coordinate of each atom:
    
    \begin{center}
    \begin{tabular}{ | c | c | c | } \hline
    $\dot{x}_1$ & $\dot{y}_1$ & $\dot{z}_1$ \\ \hline
    $\dot{x}_2$ & $\dot{y}_2$ & $\dot{z}_2$ \\ \hline
    $\dot{x}_3$ & $\dot{y}_3$ & $\dot{z}_3$ \\ \hline
    ... & ... & ... \\ \hline
    \end{tabular}
    \end{center}
    
    In the initial conditions, these may be fully specified; if they are not, a value of zero will be used for each component of each velocity that is omitted.
    
    The state coefficients indicate the population $p$ of each excited state at the start of the simulation. Populations should be provided for each excited state included in the calculations; if excess lines are provided, they will be ignored.
    
    \begin{center}
    \begin{tabular}{ | c | c | } \hline
    $p_{S_1}$ & $0.0$ \\ \hline
    $p_{S_2}$ & $0.0$ \\ \hline
    $p_{S_3}$ & $0.0$ \\ \hline
    ... & ... \\ \hline
    \end{tabular}
    \end{center}
    
%	\include{multiToC}

    \appendix
    \cleardoublepage\part{Appendix}
    
    \chapter{Sample Workflow and Helper Scripts}
    
    Each input file for \texttt{NAESMD} specifies only one single-point calculation and/or molecular dynamics trajectory. This offers several advantages, such as the fact that a swarm of independent trajectories can be handled by a separate call to \texttt{NAESMD}, executed on a separate processor, for each individual trajectory. However, performing such simulations efficiently and in an organized fashion requires the construction of a workflow that involves helper scripts to prepare input for \texttt{NAESMD} and to process and present its outputs. In particular, it is beneficial to make use of \emph{header files} that contain only the simulation parameters and omit all coordinates, velocities, and coefficients. Scripts can then be used to extract the coordinates and velocities from the output of previous runs and write a matrix of coefficients to select the initial state of the system.
    
    As an illustration, a pump-push-probe experiment on a substituted PPV derivative in solvent could be simulated as follows:
    
    \begin{enumerate}
    \item A ground-state dynamics trajectory is run using \texttt{NO2-H-10-gsl200.ceon} as input.
    \item The \texttt{s1\_gnd\_to\_exc-new.sh} script is used to extract sample geometries from various classical time points and generate input files for excitation to the first excited state.
    \item Use \texttt{launch.sh} with a PBS script \texttt{SQMscript.pbs} to queue all such jobs.
    \item Use \texttt{find-brightest-state.sh}, which uses \texttt{header-for-brightest-state} to determine the cross-density oscillator strength of each excited state with the first excited state.
    \item Use \texttt{push-to-brightest-state.sh}, which uses \texttt{ExtractStates.java} and \texttt{header-for-push-to-brightest} to excite the molecule to the "brightest" (i.e. $mA_g$ or $S_n$) state for each particular geometry and allow for relaxation (NAMD).
    \item Use the analysis tools \texttt{pop.pl}, \texttt{KE\_avg.pl}, \texttt{bla.f90}, \texttt{dihed.f90}, and others to obtain state populations as a function of a time, system kinetic energies over time, bond lengths, dihedral angles, and so on. 
    \end{enumerate}
    
    \chapter{References and Resources}

    \section{Relevant Publications}
    
    Start with our review of \texttt{NAESMD}: \url{http://dx.doi.org/10.1021/ar400263p}
    
    \noindent These publications have used \texttt{NAESMD} to study various phenomena:
    
    State-specific vibrations in dendrimers: \url{http://dx.doi.org/10.1021/jp301293e}
    
    
    Photoinduced dynamics of conjugated molecules: \url{http://dx.doi.org/10.1021/jp109522g}
    
    
    Excited-state vibrational normal modes: \url{http://dx.doi.org/10.1021/jp503350k}
    
    
    Energy transfer in weakly coupled dimers:  \url{http://dx.doi.org/10.1021/jp510557f}
    
    
    \noindent For more on trivial unavoided crossings: \url{http://dx.doi.org/10.1016/j.cplett.2013.10.052} and \url{http://dx.doi.org/10.1063/1.4732536}
    
    
    \noindent For more on parameters and numerical testing of convergence: \url{http://dx.doi.org/10.1063/1.3680565}
    
    
    \noindent For more on electronic decoherence as implemented in \texttt{NAESMD}: \url{http://dx.doi.org/10.1063/1.4809568}
    
    \section{Electronic Structure}
    
    \subsection{General Subjects}
    
    The text by Atilla Szabo and Neil Ostlund (\url{http://store.doverpublications.com/0486691861.html}) introduces the theoretical underpinnings of modern \emph{ab initio} electronic structure calculations, with an especially thorough treatment of Hartree-Fock (HF) theory. 
    
    
    \noindent David Cook's handbook (\url{http://store.doverpublications.com/0486443078.html}) provides additional instruction on practical implementations of the standard theories.
    
    
    \noindent An article by Anders Odell and others (\url{http://dx.doi.org/10.1063/1.3268338}) describes time-reversible Born-Oppenheimer molecular dynamics (TR-BOMD) and its extended Lagrangian formulation (XL-BOMD).
    
    
    \noindent Daniel Crawford's group has written a variety of tutorials in programming electronic structure calculations (\url{http://sirius.chem.vt.edu/wiki/doku.php?id=crawdad:programming}) that proceed step-by-step through the relevant physics; the discussions on excited-state HF methods here have followed theirs.
    
    
    \noindent David Shirrell also provides a variety of helpful notes on quantum chemistry (\url{http://vergil.chemistry.gatech.edu/notes/index.html}) and programming resources (\url{http://vergil.chemistry.gatech.edu/resources/programming/index.html}). The discussion on ground-state HF here uses his notation.
    
    \subsection{Davidson diagonalization}
    
    Ernest Davidson's original article: \url{http://dx.doi.org/10.1016/0021-9991(75)90065-0}
    
    
    \noindent Bowen Liu's original article is
    B. Liu, "The simultaneous expansion method for the iterative solution of several of the lowest eigenvalues and corresponding eigenvectors of large real-symmetric matrices," Technical Report LBL-8158, Lawrence Berkeley Laboratory, University of California, Berkeley, 1978.
    
    \subsection{Solvent Effects in TD-SCF}
    
    Our group's theoretical publications:
    
    
    "Optical response calculations": \url{http://dx.doi.org/10.1063/1.4905828}
    
    
    "Variational formulations and analytical gradients": \url{http://dx.doi.org/10.1063/1.4927167}
    
    \section{Molecular Dynamics}
    
    The introductory text on classical molecular simulations by Daan Frenkel and Berend Smit (\url{http://store.elsevier.com/Understanding-Molecular-Simulation/Daan-Frenkel/isbn-9780122673511/}) provides a broad overview of the basic integration schemes and statistical ensembles and the relevant thermodynamics.
    
    \noindent The original article by John Tully on fewest-switches surface hopping: \url{http://dx.doi.org/10.1063/1.459170}
    
    \subsection{Decoherence}
    
    The original article on Persico-Granucci decoherence: \url{http://dx.doi.org/10.1063/1.3489004}
    
    \noindent The original article on Truhlar decoherence: \url{http://dx.doi.org/10.1063/1.1793991}
    
    \subsection{Thermostats}
    
    An overview of the Langevin, Berendsen, and several other thermostats is given by Yanxiang Zhao: \url{http://www.math.ucsd.edu/~y1zhao/ResearchNotes/ResearchNote007Thermostat.pdf}

\end{document}
